{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/miniconda3/lib/python3.12/site-packages/ultralytics/nn/tasks.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "\n",
      "image 1/1 /home/yash/Desktop/GithubDesktop/hdfc-securities/DocumentParsing/STANDARD GLASS_Price Band Ad_Material_output/temp_page_0.png: 640x448 2 List-items, 1 Page-footer, 2 Pictures, 6 Section-headers, 1 Table, 19 Texts, 516.6ms\n",
      "Speed: 2.4ms preprocess, 516.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n",
      "\n",
      "image 1/1 /home/yash/Desktop/GithubDesktop/hdfc-securities/DocumentParsing/STANDARD GLASS_Price Band Ad_Material_output/temp_page_1.png: 640x448 11 List-items, 4 Section-headers, 7 Tables, 13 Texts, 466.6ms\n",
      "Speed: 2.2ms preprocess, 466.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n",
      "\n",
      "image 1/1 /home/yash/Desktop/GithubDesktop/hdfc-securities/DocumentParsing/STANDARD GLASS_Price Band Ad_Material_output/temp_page_2.png: 640x448 35 List-items, 1 Page-header, 1 Picture, 6 Section-headers, 6 Tables, 11 Texts, 577.0ms\n",
      "Speed: 1.8ms preprocess, 577.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n",
      "\n",
      "image 1/1 /home/yash/Desktop/GithubDesktop/hdfc-securities/DocumentParsing/STANDARD GLASS_Price Band Ad_Material_output/temp_page_3.png: 640x448 14 List-items, 8 Section-headers, 4 Tables, 25 Texts, 525.6ms\n",
      "Speed: 2.1ms preprocess, 525.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n",
      "\n",
      "image 1/1 /home/yash/Desktop/GithubDesktop/hdfc-securities/DocumentParsing/STANDARD GLASS_Price Band Ad_Material_output/temp_page_4.png: 352x640 1 Section-header, 12 Texts, 408.5ms\n",
      "Speed: 1.8ms preprocess, 408.5ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum quality cropped images saved in the 'tmp' directory.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "import os\n",
    "import pathlib\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np\n",
    "\n",
    "# List of sample PDF files to process\n",
    "pdf_list = ['STANDARD GLASS_Price Band Ad_Material.pdf']\n",
    "\n",
    "# Load the document segmentation model\n",
    "docseg_model = YOLO('yolov8x-doclaynet-epoch64-imgsz640-initiallr1e-4-finallr1e-5.pt')\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "mydict = {}\n",
    "\n",
    "def enhance_image(img):\n",
    "    \"\"\"Apply image enhancements for better quality.\"\"\"\n",
    "    # Enhance sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(1.5)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(1.2)\n",
    "    \n",
    "    # Enhance color\n",
    "    enhancer = ImageEnhance.Color(img)\n",
    "    img = enhancer.enhance(1.1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def process_pdf_page(pdf_path, page_num, docseg_model, output_dir):\n",
    "    \"\"\"Processes a single page of a PDF with maximum quality settings.\"\"\"\n",
    "    \n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "    page = pdf_doc[page_num]\n",
    "    \n",
    "     # Increase the resolution matrix for maximum quality\n",
    "    zoom = 4  # Increased zoom factor for higher resolution\n",
    "    matrix = fitz.Matrix(zoom, zoom)\n",
    "    \n",
    "    # Use high-quality rendering options\n",
    "    pix = page.get_pixmap(\n",
    "        matrix=matrix,\n",
    "        alpha=False,  # Disable alpha channel for clearer images\n",
    "        colorspace=fitz.csRGB  # Force RGB colorspace\n",
    "    )\n",
    "    \n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    # Apply image enhancements\n",
    "    img = enhance_image(img)\n",
    "    \n",
    "    # Resize with high-quality settings\n",
    "    if zoom != 1:\n",
    "        original_size = (int(page.rect.width), int(page.rect.height))\n",
    "        img = img.resize(original_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Generate a temporary filename for the page image\n",
    "    temp_img_filename = os.path.join(output_dir, f\"temp_page_{page_num}.png\")\n",
    "    \n",
    "    # Save with maximum quality settings\n",
    "    img.save(\n",
    "        temp_img_filename,\n",
    "        \"PNG\",\n",
    "        quality=100,\n",
    "        optimize=False,\n",
    "        dpi=(300, 300)  # Set high DPI\n",
    "    )\n",
    "\n",
    "    # Run the model on the image\n",
    "    results = docseg_model(source=temp_img_filename, save=True, show_labels=True, show_conf=True, boxes=True)\n",
    "\n",
    "    # Extract the results\n",
    "    page_width = page.rect.width\n",
    "    one_third_width = page_width / 3\n",
    "    \n",
    "    \n",
    "    all_coords = []\n",
    "    \n",
    "    for entry in results:\n",
    "        thepath = pathlib.Path(entry.path)\n",
    "        thecoords = entry.boxes.xyxy.numpy()\n",
    "        all_coords.extend(thecoords)\n",
    "\n",
    "\n",
    "    # Sort the coordinates into two groups and then sort each group by y1\n",
    "    left_group = []\n",
    "    right_group = []\n",
    "    for bbox in all_coords:\n",
    "            x1 = bbox[0]\n",
    "            if x1 < one_third_width:\n",
    "                left_group.append(bbox)\n",
    "            else:\n",
    "                right_group.append(bbox)\n",
    "\n",
    "\n",
    "    left_group = sorted(left_group, key=lambda bbox: bbox[1])\n",
    "    right_group = sorted(right_group, key=lambda bbox: bbox[1])\n",
    "    \n",
    "    sorted_coords = left_group + right_group\n",
    "\n",
    "\n",
    "    mydict[f\"{pdf_path} Page {page_num}\"] = sorted_coords\n",
    "\n",
    "    # Clean up the temporary image\n",
    "    os.remove(temp_img_filename)\n",
    "    pdf_doc.close()\n",
    "    \n",
    "    \n",
    "# Process each PDF in the list\n",
    "for pdf_path in pdf_list:\n",
    "    try:\n",
    "        pdf_doc = fitz.open(pdf_path)\n",
    "        num_pages = pdf_doc.page_count\n",
    "        pdf_doc.close()\n",
    "\n",
    "        output_dir = os.path.splitext(pdf_path)[0] + \"_output\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for page_num in range(num_pages):\n",
    "            process_pdf_page(pdf_path, page_num, docseg_model, output_dir)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "\n",
    "# Create the 'tmp' directory if it doesn't exist\n",
    "tmp_dir = 'tmp'\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the results and save cropped images with maximum quality\n",
    "for key, coords in mydict.items():\n",
    "    pdf_name, page_info = key.split(\" Page \")\n",
    "    page_number = int(page_info)\n",
    "\n",
    "    pdf_doc = fitz.open(pdf_name)\n",
    "    page = pdf_doc[page_number]\n",
    "    \n",
    "    zoom = 4\n",
    "    matrix = fitz.Matrix(zoom,zoom)\n",
    "\n",
    "    for i, bbox in enumerate(coords):\n",
    "        # Scale the bounding box coordinates appropriately\n",
    "        xmin, ymin, xmax, ymax = map(lambda x: x , bbox)\n",
    "            \n",
    "        # Create a rectangle from the bounding box\n",
    "        rect = fitz.Rect(xmin, ymin, xmax, ymax)\n",
    "            \n",
    "        # Crop using get_pixmap with a maximum resolution matrix\n",
    "        cropped_pix = page.get_pixmap(\n",
    "            clip=rect,\n",
    "            matrix=matrix,\n",
    "            alpha=False,\n",
    "            colorspace=fitz.csRGB\n",
    "        )\n",
    "        \n",
    "        cropped_img = Image.frombytes(\"RGB\", [cropped_pix.width, cropped_pix.height], cropped_pix.samples)\n",
    "        cropped_img = enhance_image(cropped_img)\n",
    "        \n",
    "        output_filename = os.path.join(tmp_dir, f\"{os.path.splitext(os.path.basename(pdf_name))[0]}_page{page_number}_{i}.png\")\n",
    "        \n",
    "        # Save the cropped image\n",
    "        cropped_img.save(output_filename, \"PNG\", quality=100, optimize=False, dpi=(300, 300))\n",
    "\n",
    "    pdf_doc.close()\n",
    "\n",
    "print(\"Maximum quality cropped images saved in the 'tmp' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/yash/miniconda3/lib/python3.12/site-packages/doctr/models/utils/pytorch.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(archive_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from STANDARD GLASS_Price Band Ad_Material saved to STANDARD GLASS_Price Band Ad_Material_extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "def extract_text_from_image(image_path, model):\n",
    "    \"\"\"Extracts text from a single image using DocTr.\"\"\"\n",
    "    doc = DocumentFile.from_images(image_path)\n",
    "    result = model(doc)\n",
    "    text_content = \"\"\n",
    "    for page in result.pages:\n",
    "        for block in page.blocks:\n",
    "            for line in block.lines:\n",
    "                for word in line.words:\n",
    "                    text_content += word.value + \" \"\n",
    "            text_content += \"\\n\"\n",
    "    return text_content.strip()\n",
    "\n",
    "def process_cropped_images(tmp_dir, pdf_list):\n",
    "    \"\"\"Iterates through cropped images, extracts text using DocTr and stores the text in text files.\"\"\"\n",
    "    \n",
    "    doctr_model = ocr_predictor(pretrained=True)\n",
    "    \n",
    "    for pdf_path in pdf_list:\n",
    "        pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        output_txt_path = f\"{pdf_name}_extracted_text.txt\"\n",
    "        \n",
    "        with open(output_txt_path, 'w', encoding='utf-8') as outfile:\n",
    "            \n",
    "            pdf_doc = fitz.open(pdf_path)\n",
    "            num_pages = pdf_doc.page_count\n",
    "            pdf_doc.close()\n",
    "\n",
    "            for page_num in range(num_pages):\n",
    "                \n",
    "                outfile.write(f\"Page: {page_num}\\n\")\n",
    "                \n",
    "                # Sort filenames of cropped images by chunk order\n",
    "                cropped_images_for_page = sorted([\n",
    "                    f for f in os.listdir(tmp_dir)\n",
    "                    if f.startswith(f\"{pdf_name}_page{page_num}_\") and f.endswith(\".png\")\n",
    "                ], key=lambda f: int(f.split(\"_\")[-1].split(\".\")[0]))\n",
    "                \n",
    "                for i, image_filename in enumerate(cropped_images_for_page):\n",
    "                    image_path = os.path.join(tmp_dir, image_filename)\n",
    "                    text = extract_text_from_image(image_path, doctr_model)\n",
    "                    outfile.write(f\"  Chunk {i}: {text}\\n\")\n",
    "\n",
    "        print(f\"Text extracted from {pdf_name} saved to {output_txt_path}\")\n",
    "\n",
    "# Example usage:\n",
    "tmp_dir = 'tmp' # Make sure your tmp directory exists\n",
    "pdf_list = ['STANDARD GLASS_Price Band Ad_Material.pdf'] # Your list of PDFs\n",
    "\n",
    "process_cropped_images(tmp_dir, pdf_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
