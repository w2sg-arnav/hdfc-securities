{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from pinecone-client) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from pinecone-client) (2.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.2)\n",
      "Requirement already satisfied: namex in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/yash/miniconda3/envs/myenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client\n",
    "!pip install tf-keras\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from together import Together\n",
    "\n",
    "# Ensure you have these environment variables set\n",
    "TOGETHER_AI_API_KEY = \"64880c44ef37384040dc253c954ed2f190c0e4702c3e80745e5eb78221f47376\"  # Replace with your actual API key\n",
    "PINECONE_API_KEY = \"pcsk_2aEGcj_7cwy95qcT59b57wGLdNgNquJdiTiBJXNU27UiEob5cisrASpM99fcBHPeHwxp4U\"\n",
    "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
    "PINECONE_INDEX_NAME = \"rag-chatbot-index\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file, page by page, using fitz.\n",
    "\n",
    "    Args:\n",
    "      pdf_path: Path to the input PDF file.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary where keys are page numbers (starting from 1) and values are the\n",
    "      extracted text from that page.\n",
    "      Returns an empty dictionary if fitz fails to open the PDF.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        if not pdf_document:\n",
    "            return {}  # return empty if the pdf doc is empty\n",
    "\n",
    "        page_text = {}\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            text = page.get_text()\n",
    "            page_text[page_number + 1] = text  # Page numbers start from 1\n",
    "\n",
    "        pdf_document.close()\n",
    "        return page_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during PDF extraction with fitz: {e}\")\n",
    "        return {}\n",
    "\n",
    "def semantic_chunking(text_dict: dict, chunk_size: int = 500, chunk_overlap: int = 50):\n",
    "    \"\"\"\n",
    "    Chunks the extracted text semantically.\n",
    "\n",
    "    Args:\n",
    "      text_dict: Dictionary of page-wise extracted text.\n",
    "      chunk_size: Maximum size of each chunk.\n",
    "      chunk_overlap: Number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "      A list of text chunks.\n",
    "    \"\"\"\n",
    "    all_text = \"\\n\".join(text_dict.values())\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_text(all_text)\n",
    "    return chunks\n",
    "\n",
    "def embed_and_upsert_to_pinecone(chunks: list[str]):\n",
    "    \"\"\"\n",
    "    Embeds the text chunks using HuggingFace embeddings and upserts them to Pinecone.\n",
    "    \"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\") # Choose an appropriate model\n",
    "\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "    batch_size = 32\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch_chunks = chunks[i:i + batch_size]\n",
    "        ids = [f\"chunk-{i}-{j}\" for j in range(len(batch_chunks))]\n",
    "        embeds = embeddings.embed_documents(batch_chunks)\n",
    "        metadata = [{\"text\": text} for text in batch_chunks]\n",
    "        to_upsert = list(zip(ids, embeds, metadata))\n",
    "        index.upsert(vectors=to_upsert)\n",
    "    print(f\"Upserted {len(chunks)} chunks to Pinecone.\")\n",
    "\n",
    "def generate_response(query: str, context: str, model_name: str = \"meta-llama/Llama-3-8b-chat-hf\"):\n",
    "    \"\"\"\n",
    "    Generates a response using Together AI's API with the `together` library.\n",
    "\n",
    "    Args:\n",
    "      query: The user's question.\n",
    "      context: Retrieved relevant text from Pinecone.\n",
    "      model_name: The name of the Together AI model to use.\n",
    "\n",
    "    Returns:\n",
    "      The LLM's response.\n",
    "    \"\"\"\n",
    "    if not TOGETHER_AI_API_KEY:\n",
    "        raise ValueError(\"TOGETHER_AI_API_KEY environment variable not set.\")\n",
    "\n",
    "    client = Together(api_key=TOGETHER_AI_API_KEY)\n",
    "\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=512,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def query_pinecone(query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Queries Pinecone for relevant chunks.\n",
    "\n",
    "    Args:\n",
    "      query: The user's question.\n",
    "      top_k: Number of relevant chunks to retrieve.\n",
    "\n",
    "    Returns:\n",
    "      A string containing the concatenated text of the top_k chunks.\n",
    "    \"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "    results = index.query(vector=query_vector, top_k=top_k, include_values=False, include_metadata=True)\n",
    "    context = \"\\n\\n\".join([match.metadata[\"text\"] for match in results.matches])\n",
    "    return context\n",
    "\n",
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        if not PINECONE_API_KEY:\n",
    "            raise ValueError(\"Pinecone API key must be set.\")\n",
    "        try:\n",
    "            self.pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "            if PINECONE_INDEX_NAME not in self.pc.list_indexes():\n",
    "                print(f\"Creating Pinecone index '{PINECONE_INDEX_NAME}'...\")\n",
    "                try:\n",
    "                    self.pc.create_index(\n",
    "                        name=PINECONE_INDEX_NAME,\n",
    "                        dimension=768,  # Dimension of all-mpnet-base-v2 embeddings\n",
    "                        metric=\"cosine\",\n",
    "                        spec=ServerlessSpec(\n",
    "                            cloud=\"aws\",\n",
    "                            region=PINECONE_ENVIRONMENT\n",
    "                        )\n",
    "                    )\n",
    "                    self.index = self.pc.Index(PINECONE_INDEX_NAME)\n",
    "                except Exception as e:\n",
    "                    if \"already exists\" in str(e):\n",
    "                        print(f\"Pinecone index '{PINECONE_INDEX_NAME}' already exists. Connecting to it.\")\n",
    "                        self.index = self.pc.Index(PINECONE_INDEX_NAME)\n",
    "                    else:\n",
    "                        raise e\n",
    "            else:\n",
    "                print(f\"Pinecone index '{PINECONE_INDEX_NAME}' already exists. Connecting to it.\")\n",
    "                self.index = self.pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error connecting to or creating Pinecone index: {e}\")\n",
    "\n",
    "    def ingest_pdf(self, pdf_path: Path):\n",
    "        \"\"\"Ingests the PDF, chunks it, and uploads to Pinecone.\"\"\"\n",
    "        extracted_text = extract_text_from_pdf(pdf_path)\n",
    "        if extracted_text:\n",
    "            chunks = semantic_chunking(extracted_text)\n",
    "            embed_and_upsert_to_pinecone(chunks)\n",
    "        else:\n",
    "            print(\"No text extracted from the PDF.\")\n",
    "\n",
    "    def query(self, query: str):\n",
    "        \"\"\"Queries the chatbot with a user's question.\"\"\"\n",
    "        context = query_pinecone(query)\n",
    "        if not context:\n",
    "            return \"No relevant information found in the document.\"\n",
    "        response = generate_response(query, context)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Pinecone index 'rag-chatbot-index'...\n",
      "Pinecone index 'rag-chatbot-index' already exists. Connecting to it.\n",
      "Upserted 28 chunks to Pinecone.\n",
      "Pinecone setup and ready for querying.\n",
      "==================================================\n",
      "User: Tell more about funding from this document.\n",
      "Chatbot: According to the document, the funding for a Debt Resolution Scheme (DRS) should be provided upfront and fully cover the required settlement amounts. This means that the government should provide a detailed budgetary provision to fully fund the scheme before it is announced.\n",
      "\n",
      "In other words, the government should commit to providing the necessary funds upfront to settle the debts of the impacted borrowers, rather than announcing the scheme and then trying to find the funds later. This approach is intended to ensure that the scheme is fully funded and can be implemented effectively.\n",
      "\n",
      "Additionally, the document states that lenders should be funded by the government to fully cover the required settlement amounts, implying that the government will provide the necessary funds to the lenders to settle the debts of the impacted borrowers.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "pdf_file_path = Path(\"rbi.pdf\") \n",
    "\n",
    "chatbot = RAGChatbot()\n",
    "\n",
    "chatbot.ingest_pdf(pdf_file_path) # Commenting this out to avoid re-ingestion for now\n",
    "print(\"Pinecone setup and ready for querying.\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "# Start an interactive chat session\n",
    "while True:\n",
    "    user_query = input(\"You: \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    response = chatbot.query(user_query)\n",
    "    print(f\"User: {user_query}\")\n",
    "    print(f\"Chatbot: {response}\")\n",
    "    print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
